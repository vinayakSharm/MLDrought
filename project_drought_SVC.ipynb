{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "revolutionary-shannon",
   "metadata": {},
   "source": [
    "### Soil data column index\n",
    "- fips: US county FIPS code. see: https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697\n",
    "- lat: Latitude -->\n",
    "- lon: Longitude\n",
    "- elevation: Median elevation (meters)\n",
    "- slope1: 0 % ≤ slope ≤ 0.5 %\n",
    "- slope2: 0.5 % ≤ slope ≤ 2 %\n",
    "- slope3: 2 % ≤ slope ≤ 5 %\n",
    "- slope4: 5 % ≤ slope ≤ 10 %\n",
    "- slope5: 10 % ≤ slope ≤ 15 %\n",
    "- slope6: 15 % ≤ slope ≤ 30 %\n",
    "- slope7: 30 % ≤ slope ≤ 45 %\n",
    "- slope8: Slope > 45 %\n",
    "- aspectN: North: 0˚< aspect ≤45˚ or 315˚< aspect ≤360˚\n",
    "- aspectE: East: 45˚ < aspect ≤ 135\n",
    "- aspectS: South: 135˚ < aspect ≤ 225˚\n",
    "- aspectW: West: 225˚ < aspect ≤ 315˚\n",
    "- aspectUnknown: Undefined: Slope aspect undefined; this value is used for grids where slope gradient is undefined or slope gradient is less than 2%.\n",
    "- WAT_LAND: mapped water bodies\n",
    "- NVG_LAND: barren/very sparsely vegetated land\n",
    "- URB_LAND: built-up land (residential and infrastructure)\n",
    "- GRS_LAND: grass/scrub/woodland\n",
    "- FOR_LAND: forest land, calibrated to FRA2000 land statistics\n",
    "- CULTRF_LAND: \n",
    "- CULTIR_LAND: irrigated cultivated land, according to GMIA 4.0\n",
    "- CULT_LAND: total cultivated land\n",
    "- SQ1: Nutrient availability\n",
    "- SQ2: Nutrient retention capacity\n",
    "- SQ3: Rooting conditions\n",
    "- SQ4: Oxygen availability to roots\n",
    "- SQ5: Excess salts.\n",
    "- SQ6: Toxicity\n",
    "- SQ7: Workability (constraining field management)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-taylor",
   "metadata": {},
   "source": [
    "### Weather data column index\n",
    "- fips: US county FIPS code. see: https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697\n",
    "- date: observation date\n",
    "- PRECTOT = Precipitation (mm day-1)\n",
    "- PS = Surface Pressure (kPa)\n",
    "- QV2M = Specific Humidity at 2 Meters (g/kg)\n",
    "- T2M = Temperature at 2 Meters (C)\n",
    "- T2MDEW = Dew/Frost Point at 2 Meters (C)\n",
    "- T2MWET = Wet Bulb Temperature at 2 Meters (C)\n",
    "- T2M_MAX = Maximum Temperature at 2 Meters (C)\n",
    "- T2M_MIN = Minimum Temperature at 2 Meters (C)\n",
    "- T2M_RANGE = Temperature Range at 2 Meters (C)\n",
    "- TS = Earth Skin Temperature (C)\n",
    "- WS10M = Wind Speed at 10 Meters (m/s)\n",
    "- WS10M_MAX = Maximum Wind Speed at 10 Meters (m/s)\n",
    "- WS10M_MIN = Minimum Wind Speed at 10 Meters (m/s)\n",
    "- WS10M_RANGE = Wind Speed Range at 10 Meters (m/s)\n",
    "- WS50M = Wind Speed at 50 Meters (m/s)\n",
    "- WS50M_MAX = Maximum Wind Speed at 50 Meters (m/s)\n",
    "- WS50M_MIN = Minimum Wind Speed at 50 Meters (m/s)\n",
    "- WS50M_RANGE = Wind Speed Range at 50 Meters (m/s)\n",
    "- score:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olympic-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-traffic",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "working-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electric-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soil_data=pd.read_csv('data/soil_data.csv')\n",
    "train=pd.read_csv(path+'train_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "technological-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=pd.read_csv(path+'validation_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "careful-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(path+'test_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atmospheric-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train      19300680  80.95%\n",
      "Validation  2268840   9.52%\n",
      "Test        2271948   9.53%\n",
      "Total      23841468 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_data = train.shape[0]\n",
    "valid_data = valid.shape[0]\n",
    "test_data = test.shape[0]\n",
    "total = train_data+test_data+valid_data\n",
    "\n",
    "print('Train     ',train_data,'', str(round(train_data/total*100,2))+'%')\n",
    "print('Validation ',valid_data,' ', str(round(valid_data/total*100,2))+'%')\n",
    "print('Test       ',test_data,' ', str(round(test_data/total*100,2))+'%')\n",
    "print('Total     ',total,'100.00%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-purpose",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "looking-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data preprocessing\n",
    "train['date'] = pd.to_datetime(train['date']) # parse date.\n",
    "train['score'] = train['score'].apply(pd.to_numeric).interpolate()\n",
    "train['drought_level'] = np.floor(train['score']) # classify drought level.\n",
    "train.drop(columns=['fips', 'score'], inplace=True) # remove un-necessary columns.\n",
    "train.dropna(inplace=True) # remove all examples containing NaN.\n",
    "\n",
    "# validation data preprocessing\n",
    "valid['date'] = pd.to_datetime(valid['date']) # parse date.\n",
    "valid['score'] = valid['score'].apply(pd.to_numeric).interpolate()\n",
    "valid['drought_level'] = np.floor(valid['score']) # classify drought level.\n",
    "valid.drop(columns=['fips', 'score'], inplace=True) # remove un-necessary columns.\n",
    "valid.dropna(inplace=True) # remove all examples containing NaN.\n",
    "\n",
    "# testing data preprocessing\n",
    "test['date'] = pd.to_datetime(test['date']) # parse date.\n",
    "test['score'] = test['score'].apply(pd.to_numeric).interpolate()\n",
    "test['drought_level'] = np.floor(test['score']) # classify drought level.\n",
    "test.drop(columns=['fips', 'score'], inplace=True) # remove un-necessary columns.\n",
    "test.dropna(inplace=True) # remove all examples containing NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_valid.dropna(inplace=True)\n",
    "# weather_valid['drought_level'] = np.floor(weather_valid['score'])\n",
    "# weather_valid.drop(columns=['fips', 'score'], inplace=True)\n",
    "# weather_valid['date'] = pd.to_datetime(weather_valid['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_test.dropna(inplace=True)\n",
    "# weather_test['drought_level'] = np.floor(weather_test['score'])\n",
    "# weather_test.drop(columns=['fips', 'score'], inplace=True)\n",
    "# weather_test['date'] = pd.to_datetime(weather_test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "architectural-finnish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train      19300677  80.95%\n",
      "Validation  2268838   9.52%\n",
      "Test        2271948   9.53%\n",
      "Total      23841463 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_data = train.shape[0]\n",
    "valid_data = valid.shape[0]\n",
    "test_data = test.shape[0]\n",
    "total = train_data+test_data+valid_data\n",
    "\n",
    "print('Train     ',train_data,'', str(round(train_data/total*100,2))+'%')\n",
    "print('Validation ',valid_data,' ', str(round(valid_data/total*100,2))+'%')\n",
    "print('Test       ',test_data,' ', str(round(test_data/total*100,2))+'%')\n",
    "print('Total     ',total,'100.00%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "known-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PRECTOT</th>\n",
       "      <th>PS</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>T2MWET</th>\n",
       "      <th>T2M_MAX</th>\n",
       "      <th>T2M_MIN</th>\n",
       "      <th>T2M_RANGE</th>\n",
       "      <th>TS</th>\n",
       "      <th>WS10M</th>\n",
       "      <th>WS10M_MAX</th>\n",
       "      <th>WS10M_MIN</th>\n",
       "      <th>WS10M_RANGE</th>\n",
       "      <th>WS50M</th>\n",
       "      <th>WS50M_MAX</th>\n",
       "      <th>WS50M_MIN</th>\n",
       "      <th>WS50M_RANGE</th>\n",
       "      <th>drought_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>15.95</td>\n",
       "      <td>100.29</td>\n",
       "      <td>6.42</td>\n",
       "      <td>11.40</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.10</td>\n",
       "      <td>18.09</td>\n",
       "      <td>2.16</td>\n",
       "      <td>15.92</td>\n",
       "      <td>11.31</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5.67</td>\n",
       "      <td>2.08</td>\n",
       "      <td>3.59</td>\n",
       "      <td>6.73</td>\n",
       "      <td>9.31</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.58</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.15</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>10.82</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>13.48</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.94</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.31</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.99</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>12.89</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>15.85</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.95</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.37</td>\n",
       "      <td>3.93</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>14.51</td>\n",
       "      <td>0.63</td>\n",
       "      <td>13.88</td>\n",
       "      <td>5.69</td>\n",
       "      <td>2.31</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.69</td>\n",
       "      <td>5.02</td>\n",
       "      <td>6.47</td>\n",
       "      <td>2.44</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-08</td>\n",
       "      <td>1.02</td>\n",
       "      <td>100.77</td>\n",
       "      <td>5.71</td>\n",
       "      <td>8.69</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.34</td>\n",
       "      <td>15.78</td>\n",
       "      <td>2.74</td>\n",
       "      <td>13.04</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.17</td>\n",
       "      <td>5.73</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.72</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  PRECTOT      PS  QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  T2M_MIN  \\\n",
       "3 2000-01-04    15.95  100.29  6.42  11.40    6.09    6.10    18.09     2.16   \n",
       "4 2000-01-05     0.00  101.15  2.95   3.86   -3.29   -3.20    10.82    -2.66   \n",
       "5 2000-01-06     0.01  101.31  3.49   4.99   -1.11   -1.07    12.89    -2.96   \n",
       "6 2000-01-07     0.01  101.37  3.93   5.99    0.55    0.58    14.51     0.63   \n",
       "7 2000-01-08     1.02  100.77  5.71   8.69    5.33    5.34    15.78     2.74   \n",
       "\n",
       "   T2M_RANGE     TS  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  \\\n",
       "3      15.92  11.31   3.84       5.67       2.08         3.59   6.73   \n",
       "4      13.48   2.65   1.60       2.50       0.52         1.98   2.94   \n",
       "5      15.85   3.32   1.55       2.39       0.04         2.35   2.95   \n",
       "6      13.88   5.69   2.31       3.28       1.59         1.69   5.02   \n",
       "7      13.04   8.75   2.05       2.91       1.50         1.40   4.17   \n",
       "\n",
       "   WS50M_MAX  WS50M_MIN  WS50M_RANGE  drought_level  \n",
       "3       9.31       3.74         5.58            1.0  \n",
       "4       4.85       0.65         4.19            1.0  \n",
       "5       5.22       0.05         5.17            1.0  \n",
       "6       6.47       2.44         4.03            1.0  \n",
       "7       5.73       2.01         3.72            1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-tender",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "worse-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.scatter(train['date'], train.iloc[:,-1])\n",
    "# plt.title('Date vs ' + train.columns[-1])\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel(train.columns[-1])\n",
    "# plt.savefig('Date vs '+ train.columns[-1])\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thermal-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drout_Level = ['No drought', 'D0', 'D1', 'D2', 'D3', 'D4']\n",
    "# frequency = [np.sum(df['score']==0),\n",
    "#              np.sum(df['score']==1),\n",
    "#              np.sum(df['score']==2),\n",
    "#              np.sum(df['score']==3),\n",
    "#              np.sum(df['score']==4),\n",
    "#              np.sum(df['score']==5)]\n",
    "# plt.bar(Drout_Level, frequency)\n",
    "# plt.xlabel('Drout Level')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "optical-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(df['score'], df['PRECTOT'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "upper-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,len(df.columns)):\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "#     plt.scatter(weather_train['date'], weather_train.iloc[:,i])\n",
    "#     plt.title('Date vs ' + weather_train.columns[i])\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel(weather_train.columns[i])\n",
    "# #     plt.savefig('Date vs '+ weather_train.columns[i])\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nervous-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,len(df.columns)-1):\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "#     plt.scatter(df['score'], df.iloc[:,i])\n",
    "#     plt.title('Score vs '+ df.columns[i])\n",
    "#     plt.xlabel('Score')\n",
    "#     plt.ylabel(df.columns[i])\n",
    "# #     plt.savefig('Score vs '+ df.columns[i])\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recent-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,len(df.columns)):\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "#     if weather_train.columns[i] == 'score':\n",
    "#         plt.hist(weather_train.iloc[:,i], bins=5, density=True)\n",
    "#     else:\n",
    "#         plt.hist(weather_train.iloc[:,i], density=True)\n",
    "#     plt.title('Histogram of '+ weather_train.columns[i])\n",
    "#     plt.xlabel(weather_train.columns[i])\n",
    "#     plt.ylabel('Probability')\n",
    "# #     plt.savefig('Histogram of '+ weather_train.columns[i])\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "electoral-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(weather_train.iloc[:,i], bins=5, density=True, align='left', rwidth=0.8)\n",
    "# plt.title('Histogram of Drought Level')\n",
    "# plt.xlabel('Drought Level')\n",
    "# plt.ylabel('Probability')\n",
    "# # plt.savefig('Histogram of the '+ weather_train.columns[-1])\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "entitled-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns_plot = sns.pairplot(df.loc[:, \"date\":])\n",
    "# sns_plot.savefig(\"pairplot\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-lexington",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "opposite-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare features(X) and targets(y)\n",
    "X_train = train.iloc[:1000,1:-1]\n",
    "y_train = train.iloc[:1000,-1]\n",
    "\n",
    "X_valid = valid.iloc[:100,1:-1]\n",
    "y_valid = valid.iloc[:100,-1]\n",
    "\n",
    "X_test = test.iloc[:100,1:-1]\n",
    "y_test = test.iloc[:100,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "brief-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "female-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with small size of data\n",
    "pipeline_svm = make_pipeline(StandardScaler(), SVC(kernel='rbf', C= 1, degree= 2, gamma=10, class_weight = 'balanced'))\n",
    "model = pipeline_svm.fit(X_train_weather[:5000], y_train_weather[:5000])\n",
    "pred = model.predict(X_valid_weather[:500])\n",
    "accuracy = accuracy_score(y_valid_weather[:500], pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipeline_svm = make_pipeline(StandardScaler(), SVC(class_weight = 'balanced'))\n",
    "\n",
    "param_grid = [{'svc__kernel':['linear'], 'svc__C':[0.01, 1, 10],},\n",
    "              {'svc__kernel':['poly'], 'svc__C':[0.01, 1, 10], 'svc__degree': [2,3], 'svc__gamma':[1,5,10]},\n",
    "              {'svc__kernel':['rbf'], 'svc__C':[0.01, 1, 10], 'svc__degree': [2,3], 'svc__gamma':[1,5,10]}\n",
    "             ]\n",
    "\n",
    "grid_svm = GridSearchCV(estimator=pipeline_svm,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=1,\n",
    "                        cv=5)\n",
    "model = grid_svm.fit(X_train, y_train)\n",
    "best_params = grid_svm.best_params_\n",
    "best_score = grid_svm.best_score_\n",
    "\n",
    "# Report best parameters and CV score from grid search\n",
    "print(f'best params: {best_params} | best cv score: {best_score}')\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search\n",
    "\n",
    "pipeline_svm = make_pipeline(StandardScaler(), SVC(class_weight = 'balanced'))\n",
    "\n",
    "param_grid = {'svc__kernel': [best_params['svc__kernel']],\n",
    "              'svc__C': np.linspace(best_params['svc__C']*0.1,best_params['svc__C']*10, 10),\n",
    "              'svc__degree': [best_params['svc__degree']],\n",
    "              'svc__gamma': np.linspace(best_params['svc__gamma']*0.1, best_params['svc__gamma']*10, 10)\n",
    "             }\n",
    "\n",
    "random_svm = RandomizedSearchCV(pipeline_svm,\n",
    "                                param_grid,\n",
    "                                n_iter= 5,\n",
    "                                cv = 5,\n",
    "                                scoring=\"accuracy\",\n",
    "                                verbose=1,   \n",
    "                                n_jobs=1 # you can change the n_jobs parameter to -1 if your system supports multi-prcoessing\n",
    "                               )\n",
    "\n",
    "random_svm.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_svm.best_params_\n",
    "best_score = random_svm.best_score_\n",
    "\n",
    "# Report best parameters and score from random search\n",
    "print(f'best params: {best_params} | best cv score: {best_score}')\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model test with validation data set\n",
    "pipeline_svm = make_pipeline(StandardScaler(),\n",
    "                             SVC(kernel= best_params['svc__kernel'],\n",
    "                                 C= best_params['svc__C'],\n",
    "                                 degree = best_params['svc__degree'],\n",
    "                                 gamma = best_params['svc__gamma'],\n",
    "                                 class_weight = 'balanced')\n",
    "                            )\n",
    "\n",
    "model = pipeline_svm.fit(X_train, y_train)\n",
    "pred = model.predict(X_valid)\n",
    "accuracy = accuracy_score(y_valid, pred)\n",
    "\n",
    "f1 = f1_score(y_valid, pred)\n",
    "precision = precision_score(y_valid, pred)\n",
    "recall = recall_score(y_valid, pred)\n",
    "\n",
    "result = {'f1': f1, 'acc': accuracy, 'precision': precision, 'recall': recall}\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model test with testing data set\n",
    "pipeline_svm = make_pipeline(StandardScaler(),\n",
    "                             SVC(kernel= best_params['svc__kernel'],\n",
    "                                 C= best_params['svc__C'],\n",
    "                                 degree = best_params['svc__degree'],\n",
    "                                 gamma = best_params['svc__gamma'],\n",
    "                                 class_weight = 'balanced')\n",
    "                            )\n",
    "\n",
    "\n",
    "model = pipeline_svm.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "f1 = f1_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "\n",
    "result = {'f1': f1, 'acc': accuracy, 'precision': precision, 'recall': recall}\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model test with testing data set\n",
    "pipeline_svm = make_pipeline(SVC(kernel= best_params['svc__kernel'],\n",
    "                                 C= best_params['svc__C'],\n",
    "                                 degree = best_params['svc__degree'],\n",
    "                                 gamma = best_params['svc__gamma'],\n",
    "                                 class_weight = 'balanced')\n",
    "                            )\n",
    "\n",
    "model = pipeline_svm.fit(X_train[:5000], y_train[:5000])\n",
    "pred = model.predict(X_test[:500])\n",
    "accuracy = accuracy_score(y_test[:500], pred)\n",
    "\n",
    "f1 = f1_score(y_test[:500], pred)\n",
    "precision = precision_score(y_test[:500], pred)\n",
    "recall = recall_score(y_test[:500], pred)\n",
    "\n",
    "result = {'f1': f1, 'acc': accuracy, 'precision': precision, 'recall': recall}\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
