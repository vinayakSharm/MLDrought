{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be looking at one location (fips == 8013) which is near Boulder, CO based on longitude and latitude. We use an LSTM model and XGBoost to predict drought classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'archive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(path + 'validation_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(path + 'test_timeseries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the location we will be looking at\n",
    "fips = 8013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = train[train['fips'] == fips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to get 14 day timeseries, so reformat the data\n",
    "x1 = id1[4:-4]\n",
    "y1 = x1['score']\n",
    "x1 = x1.drop(columns = ['fips', 'date', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to correct format\n",
    "x1r = x1.to_numpy()\n",
    "x1r = (x1r - np.mean(x1r)) / np.std(x1r)\n",
    "x1r = x1r.reshape(443, 14, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get every 14th drought value\n",
    "y1 = y1[13::14]\n",
    "y1 = y1.to_numpy().reshape(443, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat everything as tensors\n",
    "x1t = torch.tensor(x1r).float()\n",
    "y1t = torch.tensor(y1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation from: https://www.jessicayung.com/lstms-for-time-series-in-pytorch/\n",
    "class LSTM_nn(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim = 18, hidden_dim = 18, batch_size = 443, output_dim = 1, num_layers = 1):\n",
    "        super(LSTM_nn, self).__init__()\n",
    "        # we have an LSTM -> linear\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    " \n",
    "    def forward(self, input):\n",
    "        # Forward pass\n",
    "        _, (h1, _)  = self.lstm(input)\n",
    "        y_pred = self.linear(h1)\n",
    "        return y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 loss:  1.9517865180969238\n",
      "step:  20 loss:  1.117758870124817\n",
      "step:  40 loss:  1.1133390665054321\n",
      "step:  60 loss:  1.1024142503738403\n",
      "step:  80 loss:  1.0831773281097412\n",
      "step:  100 loss:  1.0526504516601562\n",
      "step:  120 loss:  1.0240780115127563\n",
      "step:  140 loss:  0.998091995716095\n",
      "step:  160 loss:  0.9991955757141113\n",
      "step:  180 loss:  0.938646137714386\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_nn(input_dim = 18, hidden_dim = 20, output_dim = 1, num_layers = 5)\n",
    "\n",
    "# use MSE loss to fit model. again, this is mostly taken from https://www.jessicayung.com/lstms-for-time-series-in-pytorch/\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1) # learning rate is 0.1\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # zero the gradient, then do forward pass\n",
    "    model.zero_grad()\n",
    "    y_pred = model(x1t)\n",
    "    loss = loss_fn(y_pred, y1t)\n",
    "    if (epoch % 20 == 0):\n",
    "        print(\"step: \", epoch, \"loss: \", loss.item())\n",
    "    # then update parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro train:  0.22952126199536066\n"
     ]
    }
   ],
   "source": [
    "# get the f1 macro:\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# we'll treat this as classification by taking the floor of each drought score. any negative values output will count as 0\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "f1macro = sklearn.metrics.f1_score(relu(np.floor(y_pred.detach().numpy())), np.floor(y1t.detach().numpy()), average = 'macro')\n",
    "print(\"f1 macro train: \", f1macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.654627539503386\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(relu(np.floor(y_pred.detach().numpy())) == np.floor(y1t.detach().numpy()))\n",
    "print(\"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1_test = test[test['fips'] == fips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test = id1_test[1:-2]\n",
    "y1_test = id1_test['score']\n",
    "x1_test = x1_test.drop(columns = ['fips', 'date', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape testing X to sequence format\n",
    "x1r_test = x1_test.to_numpy()\n",
    "x1r_test = (x1r_test - np.mean(x1r_test)) / np.std(x1r_test)\n",
    "x1r_test = x1r_test.reshape(52, 14, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get drought classification for every two weeks\n",
    "y1_test = y1_test[13::14]\n",
    "y1_test = y1_test.to_numpy().reshape(52, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "x1t_test = torch.tensor(x1r_test).float()\n",
    "y1t_test = torch.tensor(y1_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model(x1t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro test:  0.23678861788617883\n"
     ]
    }
   ],
   "source": [
    "f1macro = sklearn.metrics.f1_score(relu(np.floor(y_pred_test.detach().numpy())), np.floor(y1t_test.detach().numpy()), average = 'macro')\n",
    "print(\"f1 macro test: \", f1macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7159, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_pred_test, y1t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6346153846153846"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "np.mean(relu(np.floor(y_pred_test.detach().numpy())) == np.floor(y1t_test.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deterministic model\n",
    "np.mean(np.floor(y1t_test.detach().numpy()) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get floor for classification, drop na values\n",
    "id1['drought_level'] = np.floor(id1['score'])\n",
    "id1.drop(columns = ['fips', 'date', 'score'], inplace = True)\n",
    "id1.dropna(inplace = True)\n",
    "\n",
    "id1_test['drought_level'] = np.floor(id1_test['score']) \n",
    "id1_test.drop(columns = ['fips', 'date', 'score'], inplace = True) \n",
    "id1_test.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correct columns\n",
    "X_train2 = id1.iloc[:,0:-1]\n",
    "y_train2 = id1.iloc[:,-1]\n",
    "\n",
    "X_test2 = id1_test.iloc[:,0:-1]\n",
    "y_test2 = id1_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:16:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=2, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_classifier = xgboost.XGBClassifier(n_estimators = 2)\n",
    "xg_classifier.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18264705882352944"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = xg_classifier.predict(X_test2)\n",
    "sklearn.metrics.f1_score(y_test2, y_preds, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6476190476190476"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy:\n",
    "np.mean(y_test2 == y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random stratifier:\n",
    "dummy_classifier = sklearn.dummy.DummyClassifier(strategy = \"stratified\")\n",
    "dummy_classifier.fit(X_train2, y_train2) # fit classifier on training data\n",
    "\n",
    "# get predictions for testing data\n",
    "ydummy_pred = dummy_classifier.predict(X_test2)\n",
    "sklearn.metrics.f1_score(ydummy_pred, y_test2, average = 'macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
